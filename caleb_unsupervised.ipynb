{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438677c-379c-4129-9cfd-e90e73c60c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-12 02:32:48.664800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-12 02:32:49.554755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Let's start with necessary imports\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4c5ae4b-24fc-47b9-91ae-0be5177d7353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and normalize it\n",
    "background = np.load('background.npz')['data']\n",
    "stds = np.std(background, axis=-1)[:, :, np.newaxis]\n",
    "background = background/stds\n",
    "background = np.swapaxes(background, 1, 2)\n",
    "\n",
    "bbh = np.load('bbh_for_challenge.npy')\n",
    "stds = np.std(bbh, axis=-1)[:, :, np.newaxis]\n",
    "bbh = bbh/stds\n",
    "bbh = np.swapaxes(bbh, 1, 2)\n",
    "\n",
    "sglf = np.load('sglf_for_challenge.npy')\n",
    "stds = np.std(sglf, axis=-1)[:, :, np.newaxis]\n",
    "sglf = sglf/stds\n",
    "sglf = np.swapaxes(sglf, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f569aca-bbb3-4a51-b725-fe45346dc05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train/test shapes: (80000, 200, 2) (20000, 200, 2)\n",
      "y train/test shapes: (80000, 200, 2) (20000, 200, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create train and test datasets\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "     background, background, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f'x train/test shapes: {x_train.shape} {x_test.shape}')\n",
    "print(f'y train/test shapes: {y_train.shape} {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a004c75-5759-4b08-9623-2cfb137aa8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def transformer_encoder(self, inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "        x = layers.MultiHeadAttention(\n",
    "            key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
    "        )(inputs, inputs)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = x + inputs\n",
    "\n",
    "        x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(res)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        return x + res\n",
    "\n",
    "    def dense_decoder(self, inputs, ff_dim, output_dim, dropout=0):\n",
    "        # Flatten the input to apply dense layers\n",
    "        x = layers.Flatten()(inputs)\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        res = layers.Dense(ff_dim)(x)  # Align dimensions for residual\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        x = x + res\n",
    "\n",
    "        x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.Dense(np.prod(inputs.shape[1:]))(x)  # Output dimension should match the flattened input dimension\n",
    "        x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "\n",
    "        # Reshape back to original input shape\n",
    "        x = layers.Reshape(inputs.shape[1:])(x)\n",
    "        return x + inputs  # Adding input directly, assuming output_dim matches inputs shape[-1]\n",
    "\n",
    "    def build_model(self, input_shape, head_size, num_heads, ff_dim, num_transformer_blocks, num_dense_blocks, dropout=0, mlp_dropout=0):\n",
    "        inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "        # Encoder\n",
    "        x = inputs\n",
    "        for _ in range(num_transformer_blocks):\n",
    "            x = self.transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
    "\n",
    "        encoder_output = x\n",
    "\n",
    "        # Decoder\n",
    "        x = encoder_output\n",
    "        for _ in range(num_dense_blocks):\n",
    "            x = self.dense_decoder(x, ff_dim, input_shape[-1], dropout)\n",
    "\n",
    "        # Output layer\n",
    "        outputs = layers.Dense(input_shape[-1])(x)\n",
    "\n",
    "        self.ae = keras.Model(inputs, outputs)\n",
    "        self.ae.compile(loss=\"mse\", optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n",
    "\n",
    "    def predict(self, X, batch_size=32):\n",
    "        return np.mean((self.ae.predict(X, batch_size=batch_size) - X) ** 2, axis=(1,2))\n",
    "\n",
    "    def __call__(self, inputs, batch_size=64):\n",
    "        return self.ae.predict(inputs, batch_size=batch_size)\n",
    "\n",
    "    def save(self, path):\n",
    "        self.ae.save(os.path.join(os.path.dirname(__file__), 'model.keras'))\n",
    "\n",
    "    def load(self):\n",
    "        self.ae = keras.models.load_model(os.path.join(os.path.dirname(__file__), 'model.keras'))\n",
    "\n",
    "    def fit(self, x_train, **kwargs):\n",
    "        history = self.ae.fit(x_train, x_train, **kwargs)\n",
    "        return history\n",
    "\n",
    "# Example usage:\n",
    "input_shape = x_train.shape[1:]\n",
    "head_size = 64\n",
    "num_heads = 2\n",
    "ff_dim = 64\n",
    "num_transformer_blocks = 2\n",
    "num_dense_blocks = 1\n",
    "dropout = 0.1\n",
    "\n",
    "# build the model\n",
    "autoencoder = Model()\n",
    "autoencoder.build_model(\n",
    "    input_shape=input_shape,\n",
    "    head_size=head_size,\n",
    "    num_heads=num_heads,\n",
    "    ff_dim=ff_dim,\n",
    "    num_transformer_blocks=num_transformer_blocks,\n",
    "    num_dense_blocks=num_dense_blocks,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# Assuming x_train is your input data\n",
    "history = autoencoder.fit(\n",
    "    x_train, # For autoencoders, input is same as output\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07458e65-2efe-4318-b24c-515bae3409d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
